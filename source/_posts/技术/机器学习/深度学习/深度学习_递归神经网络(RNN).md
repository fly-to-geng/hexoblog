---
title: 深度学习_递归神经网络(RNN)
toc: true

tags:
  - RNN
  - 递归神经网络
date: 2017-05-10 10:14:24
---

递归神经网络，或者循环神经网络，英文名称Recurrent Neural Networks，是一种神经元上带环的神经网络。它的结构允许保留信息，传统的神经网络做不到这一点，这也许是传统的神经网络的主要缺点之一。递归神经网络主要的应用领域是**语音识别**，**语言建模**，**翻译**，**图像字幕**...

<!--more-->

递归神经网络的神经元模型：
![](2017-05-10_102612.png)
神经元上的自传递(那个环)允许信息在网络训练的不同步骤之间保留信息。其实这个模型并不复杂，因为可以把它展开成一系列普通的神经元，如下图，
![](2017-05-10_102844.png)
上图中每一个神经元表示一个状态，从一个状态到下一个状态时，神经元保存的信息可以传递下去。

RNN的基本考量是可以利用之前的信息加强对现在的信息的理解，例如用一个完整视频的前几帧辅助识别后面几帧出现的内容，再比如，用一个电影的前半个小时的剧情预测后面的剧情。如果RNN能够实现这些，无疑会是非常有用的。

普通的RNN只能处理时间上接近的联系，比如用前一帧的信息预测后一帧，后两帧，但是无法处理时间上很长的联系，例如用一个小时之前的一帧预测现在的一帧。这是因为梯度随着层数的加深会很快消失，类似神经网络中遇到的那样。

有一种特殊结构的RNN网络可以克服上面的问题，使得长时间的联系可以实现，该网络的名字叫做LSTM(Long Short Term Memory networks)。

## LSTM

Long Short Term Memory networks, 是一种特殊的RNN，

普通的RNN在神经元自己的环上从一个步骤到下一个步骤的时候，都会经过一个简单函数的处理，类似$x2 = tanh(x1)$;
![](2017-05-10_104948.png)
而LSTM与之不同的是有一个更为复杂的处理，这是这个处理保证了它可以保留长期的信息。
![](2017-05-10_105051.png)
![](2017-05-10_105226.png)
下面我们详细介绍这个复杂的处理过程。
![](QQ截图20170510112351.png)
最上面的水平线保持了原来的数据的不变性（只经过了简单的线性变换），这个叫做cell state.

![](2017-05-10_112918.png)
这样的图标表示一个simoid神经元，输出范围是[0,1].
![](2017-05-10_113009.png)
![](2017-05-10_113224.png)
![](2017-05-10_113026.png)
![](2017-05-10_113334.png)
上面的图展示了每一步的计算过程，其中\*表示的是向量的乘法。

除了这种标准的结构，还有许多其他的变种，适用于不同的情况。

**参考文献**：

http://colah.github.io/posts/2015-08-Understanding-LSTMs/
