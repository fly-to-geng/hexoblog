---
title: 机器学习_范数
toc: true

tags:
  - 范数
date: 2016-06-16 17:42:54
---
监督学习的一般过程是训练一个模型，根据给出的X计算出y, 然后最小化计算出来的y与真实的y之间的误差。
如果仅仅考虑最小化这个误差，很容易使这个误差为0，就是所有的训练数据都得到了正确的y.但是真实的情况是
训练数据中往往存在噪声，这些噪声和y并没有关系，当训练好的模型应用到模型没有见过的测试数据上时，效果会很差，
这就是过拟合(overfitting)。范数就是一种为了减小过拟合现象引入的参数。常用的范数有L0,L1,L2,核范数等。
<!-- more -->

# L0 范数

L0范数是指 向量（模型参数组成的向量）中非0元素的个数。L0范数也可以用来实现稀疏，但是不如L1范数应用广泛。

# L1范数（Lasso）

L1范数是指 向量中各个元素绝对值之和。可以用来实现稀疏，使用L1范数会使求的的参数很多为0，这样就可以实现稀疏。
稀疏可以用来做特征选择。那些系数为0的参数代表的特征就去掉了。

# L2范数 （Ridge）

L2范数是指 向量各元素的平方和然后求平方根。L2范数可以使得参数很小，接近于0，但是不是0（L1范数参数是0）防止过拟合，提升模型的泛化能力。

>L2范数的作用
>有利于处理ill-condition的情况，所谓的ill-condition,就是X变化很小的时候，y的变化很大。因为X都是存在误差的，这样如果X矩阵是ill-condition的，
>推测出的结果就不可信。参考资料（http://blog.csdn.net/zouxy09/article/details/24971995/）

# 核范数

核范数是指 矩阵奇异值的和

参考资料：

```bash
[1] http://fastml.com/large-scale-l1-feature-selection-with-vowpal-wabbit/

[2] http://www.stat.purdue.edu/~vishy/introml/notes/Optimization.pdf

[3] http://www.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf

[4] GradientDescent, Wolfe's Condition and Logistic Regression

[5] http://nm.mathforcollege.com/mws/gen/04sle/mws_gen_sle_spe_adequacy.pdf
```
