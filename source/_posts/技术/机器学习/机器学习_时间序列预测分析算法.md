---
title: 机器学习_时间序列预测分析算法
toc: true

tags:
  - 时间序列
  -
date: 2017-05-11 16:08:13
---
预测问题是机器学习中很重要的一个问题，它是根据过去已经存在的数据预测未来可能的情况。本文通过一个著名的波士顿抢劫案的数据集来说明预测问题的来龙去脉。

<!-- more -->


## AR自回归模型预测

### 数据集

[Daily Female Births Dataset](https://datamarket.com/data/set/235k/daily-total-female-births-in-california-1959#!ds=235k&display=line)

This dataset describes the number of daily female births in California in 1959.

它的结构很简单，每一行是一天的数据，每一行有两个数据，第一个是日期，第二个是人数。

### 用Python加载数据集

```python
from pandas import Series
from matplotlib import pyplot
file_path = r'D:\deeplearning\Forecasting\daily-total-female-births-in-cal.csv'
series = Series.from_csv(file_path, header=0)
print(series.head())
series.plot()
pyplot.show()
```

series.plot()是pandas的Series自己提供的数据可视化方法。

### 选择一种预测模型

这里我们先选择使用最广泛的自回归模型来看看。

#### Autoregressive model

自回归模型（英语：Autoregressive model，简称AR模型），是统计上一种处理时间序列的方法，用同一变数例如x的之前各期，亦即$x_1$至 $ x_{t-1}$来预测本期 $x_{{t}}$ 的表现，并假设它们为一线性关系。因为这是从回归分析中的线性回归发展而来，只是不用x预测y，而是用x预测x（自己）；所以叫做自回归。
自回归模型被广泛运用在经济学、信息学、自然现象的预测上.

自回归模型（Autoregressive Model）是用自身做回归变量的过程，即利用前期若干时刻的随机变量的线性组合来描述以后某时刻随机变量的线性回归模型，它是时间序列中的一种常见形式.

P阶自回归模型，记作AR(p),含义是序列中$x_t$是前p个序列$(x_{t-6},x_{t-5},x_{t-4},x_{t-3},x_{t-2},x_{t-1})$ 和误差项通过线性组合而成的。

**优点与限制**

1. 必须具有自相关，自相关系数（$\varphi _{i}$）是关键。如果自相关系数(R)小于0.5，则不宜采用，否则预测结果极不准确。
2. 自回归只能适用于预测与自身前期相关的经济现象，即受自身历史因素影响较大的经济现象，如矿的开采量，各种自然资源产量等；对于受社会因素影响较大的经济现象，不宜采用自回归，而应改采可纳入其他变数的向量自回归模型。

#### 使用AR模型的训练和测试

```python
# 下面该选择用来预测的模型了，
# 这里我们随便选择一个 AR 模型
from statsmodels.tsa.ar_model import AR
from sklearn.metrics import mean_squared_error
import numpy

# create a difference transform of the dataset
def difference(dataset):
	diff = list()
	for i in range(1, len(dataset)):
		value = dataset[i] - dataset[i - 1]
		diff.append(value)
	return numpy.array(diff)

# Make a prediction give regression coefficients and lag obs
def predict(coef, history):
	yhat = coef[0]
	for i in range(1, len(coef)):
		yhat += coef[i] * history[-i]
	return yhat

# split dataset
X = difference(series.values)
size = int(len(X) * 0.66)
train, test = X[0:size], X[size:]
# train autoregression
model = AR(train)
model_fit = model.fit(maxlag=6, disp=False)
window = model_fit.k_ar
coef = model_fit.params
# walk forward over time steps in test
history = [train[i] for i in range(len(train))]
predictions = list()
for t in range(len(test)):
	yhat = predict(coef, history)
	obs = test[t]
	predictions.append(yhat)
	history.append(obs)
error = mean_squared_error(test, predictions)
print('Test MSE: %.3f' % error)
# plot
pyplot.plot(test)
pyplot.plot(predictions, color='red')
pyplot.show()
```

上面我们使用的是AR(6)模型。就是用前6个数据去预测第七个数据。如此循环，不断调整参数，减小损失函数。

![](2017-05-11_172946.png)


保存训练好的模型，以便以后的使用：

```python
# save model to file
model_fit.save('ar_model.pkl')
# save the differenced dataset
numpy.save('ar_data.npy', X)
# save the last ob
numpy.save('ar_obs.npy', [series.values[-1]])
```


与之对应的加载模型的方法

```python
# load the AR model from file
from statsmodels.tsa.ar_model import ARResults
import numpy
loaded = ARResults.load('ar_model.pkl')
print(loaded.params)
data = numpy.load('ar_data.npy')
last_ob = numpy.load('ar_obs.npy')
print(last_ob)
```

## 线性回归预测

## 使用神经网络实现简单的线性回归

### 数据集

The problem that we will look at in this tutorial is the [Boston house price dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data).

The dataset describes 13 numerical properties of houses in Boston suburbs and is concerned with modeling the price of houses in those suburbs in thousands of dollars. As such, this is a regression predictive modeling problem. Input attributes include things like crime rate, proportion of nonretail business acres, chemical concentrations and more.

[数据集的详细说明](http://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)

### 使用keras用简单的神经网络模拟线性回归

我们使用[Keras](https://keras.io/)构造一个简单的全连接的神经网络来模拟回归模型，做出预测。

```python
# -*- coding: utf-8 -*-
"""
Created on Thu May 11 14:44:12 2017

@author: FF120
"""

import numpy
import pandas
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# load dataset
data_file_path = r'D:\deeplearning\Boston house price dataset\housing.data.txt'
dataframe = pandas.read_csv(data_file_path, delim_whitespace=True, header=None)
dataset = dataframe.values
# split into input (X) and output (Y) variables
X = dataset[:,0:13]
Y = dataset[:,13]

	# create model
  # 该模型一共有三层，第一层是输入，有13个神经元；第二层是也有13个神经元，激活函数是relu
  # 第三层只有一个神经元，是输出，没有激活函数
model = Sequential()
model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))
	# Compile model
model.compile(loss='mean_squared_error', optimizer='adam')


## 划分训练集和测试集
x_train = X[0:400,:]
x_test = X[400:,:]
y_train = Y[0:400]
y_test = Y[400:]
model.fit(x_train,y_train,epochs=1000,batch_size=10,shuffle=True,)
predicted_y = model.predict(x_test)
print(y_test)

from matplotlib import pyplot
pyplot.plot(predicted_y)
pyplot.plot(y_test, color='red')
pyplot.show()
```


epochs = 1000 的时候的结果：

![](2017-05-11_191517.png)

epochs = 1500 的时候的结果：

![](2017-05-11_192035.png)

我们可以借助keara提供的scikit-learn API来和scikit-learn互动，这样我们可以更加方便的使用scikit-learn实现的交叉验证方式来测试我们的神经网络。

首先，我们把定义神经网络模型的代码写成函数的形式：

```python
# define base model
def baseline_model():
	# create model
	model = Sequential()
	model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))
	model.add(Dense(1, kernel_initializer='normal'))
	# Compile model
	model.compile(loss='mean_squared_error', optimizer='adam')
	return mode
```

我们使用KerasRegressor来打通和scikit-learn的连接。'nb_epoch=100, batch_size=5, verbose=0'这些参数都是kears模型fit的时候需要的参数。

```python
# evaluate model with standardized dataset
estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=5, verbose=0)
```

K折交叉验证和结果的评估：

```python
kfold = KFold(n_splits=10, random_state=seed)
results = cross_val_score(estimator, X, Y, cv=kfold)
print("Results: %.2f (%.2f) MSE" % (results.mean(), results.std()))
```

为了方便理解和描述，我们这里只是介绍一下交叉验证的实现方法，并不使用。我们还是使用上面完整一段代码里用的手工划分训练集和测试集的方法。

### 神经网络结构的调整和性能的比较

我们改变一下上面定义的神经网络的结构，看结果是不是会发生变化。

```python
model.add(Dense(13, input_dim=13, kernel_initializer='normal', activation='relu'))
model.add(Dense(6, kernel_initializer='normal', activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))
```

原来的结构是`13 inputs ->13 -> 1`, 现在变成了`13 inputs -> 13 -> 6 -> 1`. epochs = 1000 得到的结果是：

![](2017-05-11_193546.png)

可以看到并没有太大的提高。我们再尝试使用更多的隐层神经元试试。

```python
model = Sequential()
model.add(Dense(20, input_dim=13, kernel_initializer='normal', activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))
```

![](2017-05-11_193854.png)

还是没有太大的提高，估计这种简单的模型也只能是这个水平了。

参考资料：<http://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/>



 参考文献：

 1. <http://machinelearningmastery.com/make-predictions-time-series-forecasting-python>

 2. <http://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras>

 3. <http://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python>
