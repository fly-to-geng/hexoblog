---
title: 大数据基础框架
toc: true

tags:
  - HDFS
date: 2017-10-06 20:21:59
---

大数据系统最初由google公布的一篇论文引起，后来发展出hadoop和一系列工具，后来又有spark，本文介绍在大数据处理领域一些常用工具的基本原理。

<!-- more -->

## HDFS

`hadoop distributed file system (HDFS)` 是脱胎于`google file system`的一个分布式文件系统,据说，其性能并没有达到GFS的水平，只是根据谷歌论文的原理的一个开源实现版本。 HDFS的特定有以下几点：

1. 同时保存多个副本(默认三个)，提供容错机制，副本丢失能够自动恢复。
2. 运行在不可靠机器上(廉价机器上)
3. 适合大数据的处理，HDFS默认将文件分成64M大小的block, 将block按照键值对的方式存储在HDFS上。将映射关系保存在内存中。

### HDFS的构成

`HDFS`是主从结构(`master/slave`结构)，主要由`NameNode`和`DataNode`组成。`NameNode` 是Master节点，负责整个系统的结构信息和调度控制，`DataNode`是slave节点，负责存储数据。除此之外，一般还有一个`SecondaryNameNode`节点，是`NameNode`节点的备份，负责承担一部分`NameNode`的工作，定时备份`NameNode`的数据，当`NameNode`出现故障的时候，可以从`SecondaryNameNode`恢复数据。

- NameNode
- DataNode

### 写文件操作

![HDFS写文件示意图](26162921-2de9d28df9b54fe6a97a6fd88f1cb03f.jpg)

如上图，该图表示一个win7系统的电脑要把一个100M的文件写入一个HDFS文件系统。该HDFS文件系统运行在一个Hadoop集群之上，集群拥有一个NameNode(NN)节点，8个DataNode(DN)节点，有三个机架(rack1,rack2,rack3), 全部在一个机房内。

1. client把文件分割程64M大小(HDFS文件系统的默认大小)，生成两个文件块，一个64M， 一个36M。

2. client向NameNode发送写文件的请求。

3. NameNode收到请求之后，查询自己数据中记录的整个HDFS文件系统的信息，确定这些数据写入哪些DataNode节点中，并且记录下该信息，返回该信息给请求的主机。

> 假设分配的情况如下：

> - block1: host2,host1,host3
> - block2: host7,host8,host4

>分配DataNode节点的规则为： 如果client为DataNode节点，那么副本1存储在与client相同的节点上，副本2存储在不同机架的节点上，副本三存储在同副本2相同机架上的不同节点； 如果client不是DataNode节点，则副本1随机选择一个节点，副本2选择不同的机架，副本3同副本2的机架的不同节点。

4. client根据收到的写入信息,把block1写入第一个主机host2, 整个写入过程是流式写入的，数据被分割策划那个64K的小数据包写入，每次写完64K，host2将自己刚刚得到的64K数据写入host1, host1得到64K之后写入host3, 实际上客户端只需要向host2写入一次数据，数据就可以有三个备份。当第一个block写完之后，host2,host1,host3向NameNode, host2向client发送信息说明数据已经写完。

5. client收到信息之后发送第二个block，过程和第一个block一样。

6. 第二个block写完之后，数据彻底写完，写文件的过程就结束了。

通过写文件的过程和不同副本的分配策略可以看出，挂掉一个节点设置整个机架都是没有关系的，总能从其他的地方找回这些丢失的数据。

### 读文件操作

![HDFS读取文件示意图](26163017-fc613879835c402886b75e0593ca52ed.jpg)

如图，win7客户端要从HDFS文件系统上读取一个100M大小的的文件，该文件在HDFS中有两个数据块组成:block1,block2.

1. client 向NameNode 发送读取文件的请求。

2. NameNode收到读取文件的请求，查询自己存储的元信息，返回block1和block2的存储位置： `block1: host2,host1,host3; block2: host7,host8,host4`;

3. 客户端收到NameNode的消息，去机器host2读取block1,去机器host7读取block2,读取完成之后合并成一个完整的文件，整个读文件的过程就结束了。如果client位于DataNode内，则优先读取本机架上的数据。

参考文献：[HDFS读写原理](http://www.cnblogs.com/laov/p/3434917.html)

## MapReduce

MapReduce 是一个计算框架，就是在特定的输入上产生特定的输出。输入和输出都是`<key,val>`这种键值对的形式。 Mapper就是对每个个体进行操作，不涉及个体之间的相互作用，例如转换格式，分割字符串等，这样Mapper这个阶段做的工作可以在许多机器上并行的执行， Reducer执行一些需要不同条目之间协同才能完成的操作，例如计数，求和，需要遍历所有的条目才能得到结果。Reducer任务会在不同的机器上传递结果，得到最终的结果之后再返回。

![MapReduce运行机制](x.png)

1. 在执行Map计算之前，先要根据文件的大小和HDFS的配置情况进行分片(input split), 假设HDFS默认的block大小是64M，而本次任务的输入有3个文件，一个10M，一个70M，一个128M，则10M的文件会被分成一片，70M的文件会被分成两片，128M的文件也会被分成两片。 分片操作仅仅计算出一个分片的长度和每个分片对应的数据的索引位置，并不改变原来的数据。

2. 执行程序中定义好的Map操作，Map在各个数据节点上独立的执行，相互之间没有影响。

3. combiner阶段：目的是在本地机器上执行reduce操作，把可以在本地机器上合并的结果先执行了，避免以后需要大量传输数据(机器之间传输数据 的开销往往是分布式系统最大的瓶颈). 例如求最大值，最小值和求和等操作，可以Map之后可以现在各个数据节点求出整个数据节点的最大值，作为一个结果输出，之后的reduce操作会大大减少结果的传输负担。

4. shuffle阶段： 将Mapper阶段的输出作为Reducer阶段的输入数据。

5. Reduce阶段： 执行用户编写的reduce函数，得出结果之后存储在HDFS文件系统之上。

![Map-Shuffle-Reduce过程解析](1.png)

参考文献:[cnblogs](http://www.cnblogs.com/sharpxiajun/p/3151395.html)

## Spark

### 弹性分布式数据集(RDD)

Spark 底层存储数据的时候使用的是Hadoop的HDFS分布是文件系统，所以可以存储任何兼容Hadoop的数据源，例如Hbase. Spark 在逻辑上把数据存储在一个一个的RDD中，一个RDD可以看作一张表格，可以保存任何类型的数据。RDD是不可改变的，任何改变RDD的操作都会返回一个全新的RDD，spark的所有操作，在逻辑上都是针对RDD的操作。 RDD支持两种操作：transformation 和 action . transformation 是对RDD执行一个变换操作，不会立即计算，只是记录了应该在该RDD上执行这样的操作。 action 一般会是一个reduce操作， 会立刻执行，就是之前定义的所有transformation操作和当前定义的action操作。

- **transformation**: 对RDD执行一个变换，返回一个新的RDD。可用的操作有map,filter,flatMap, groupByKey, reduceByKey 等。

- **action**: 在该RDD对象上执行之前定义的所有操作(包括所有的transformation操作)， 返回计算的结果。 可用的操作有reduce, collect, count, first, countByKey 等。

### WordCount 程序

使用spark运行一个统计单词个数的程序十分简单，这个过程可以帮助我们了解spark是如何工作的。

读取文本文件并生成RDD，将RDD缓存在内存中，缓存的RDD不需要从头开始计算，如果RDD没有缓存，就算过后的RDD会被立刻丢弃，每次想要得到结果都需要从头开始计算。

```java
/* SimpleApp.scala */
import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf

object SimpleApp {
  def main(args: Array[String]) {
    val logFile = "YOUR_SPARK_HOME/README.md" // 应该是你系统上的某些文件
    val conf = new SparkConf().setAppName("Simple Application")
    val sc = new SparkContext(conf)
    val logData = sc.textFile(logFile, 2).cache()
    val numAs = logData.filter(line => line.contains("a")).count()
    val numBs = logData.filter(line => line.contains("b")).count()
    println("Lines with a: %s, Lines with b: %s".format(numAs, numBs))
  }
}
```

这个程序仅仅是在 Spark README 中计算行里面包含 'a' 和包含 'b' 的次数.

### Spark 框架的主要内容

![Spark生态系统](spark-stack-new.png)

- `spark streaming` : 基于微批量方式的计算和处理，可以用于处理实时的流数据。它使用DStream，简单来说就是一个弹性分布式数据集（RDD）系列，处理实时数据。

- `spark SQL` : 可以通过JDBC API将Spark数据集暴露出去，而且还可以用传统的BI和可视化工具在Spark数据上执行类似SQL的查询。用户还可以用Spark SQL对不同格式的数据（如JSON，Parquet以及数据库等）执行ETL，将其转化，然后暴露给特定的查询。

- `spark mlib` : 是一个可扩展的Spark机器学习库，由通用的学习算法和工具组成，包括二元分类、线性回归、聚类、协同过滤、梯度下降以及底层优化原语。

- `spark graphx` : 是用于图计算和并行图计算的新的（alpha）Spark API。通过引入弹性分布式属性图（Resilient Distributed Property Graph），一种顶点和边都带有属性的有向多重图，扩展了Spark RDD。为了支持图计算，GraphX暴露了一个基础操作符集合（如subgraph，joinVertices和aggregateMessages）和一个经过优化的Pregel API变体。此外，GraphX还包括一个持续增长的用于简化图分析任务的图算法和构建器集合。

- `blinkDB` : 一个近似查询引擎，用于在海量数据上执行交互式SQL查询。BlinkDB可以通过牺牲数据精度来提升查询响应时间。通过在数据样本上执行查询并展示包含有意义的错误线注解的结果，操作大数据集合。

- `sparkR` : R语言的spark接口

## HBASE

HBase, Hadoop Database, 是Google Bigtable的开源实现，是一个面向列的，可伸缩的分布式存储系统，它的底层文件存储使用的是HDFS。

**`HBase`的存储逻辑**

表由行和列组成，列被分组，若干个列组成一个列簇（row family）,表在定义的时候，就必须声明所有的列簇，但是列簇内包含几个列可以动态增加(这也体现了面向列的存储这一方面). 同一个列簇使用相同的前缀为其命名，例如`temperature:air` 和  `temperature:dew` 都是`temperature`列簇的成员, `HBase`的每个列簇称作一个`store`，同一个列簇的数据会存储在同一个目录下，可能会分割成多个文件存储。


每个行由一个键表示，行键是一个字节数组，行按照行键进行排序。

行列交叉的位置称作`Cell`，每个cell都有版本，以时间戳标识，这个标识可以自己定义。也就是说，Hbase中的每个数据都是有版本的，数据按照时间倒序排列，最新的数据排列在最前面。cell中的内容是字节数组，不带格式,HBase存储的数据都是无格式的。唯一的确定一个cell需要下面这些数据：row key(行键), column:label(列簇的前缀的列的名称)， version(版本号)， 行键用来确定是哪一行，column:label确定是哪一列，版本号确定是哪个版本的数据，这样可以唯一的确定一个单元格里的数据。


HBase自动把表格水平划分程若干region, 每个region都是连续的若干行数据(类似数据库的水平分割).

**HBase的物理存储结构**

一个Table最初只有一个Region,随这行的数量的增加，当超过一个既定的阈值的时候，Region就会等分为2个。 相同的Region保证存储在相同的机器上，不同的Region可以存储在不同的机器上，叫做region server。

每个Region存储的若干行和这些行的所有列。每个Region的内部存储是这样的：Region 由一个或者多个store组成，每个store存储一个列簇， 每个store包括一个memStore和0个或者多个storefile,storefile是存储的最小单位，以HFile的格式保存在HDFS文件系统上。

![HBase架构示意图](QQ截图20171007212611.png)

**HBase的运行**

HBase 由一个主节点master和若干个RegionServer组成，主节点的负载较轻，主要负责引导初始安装，分配区域给已经注册的区域服务器，恢复区域服务器的故障等。 区域服务器负责自己存储的若干个区域的读写工作。


## Hive

hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析

Hive是建立在 Hadoop 上的数据仓库基础构架。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在 Hadoop 中的大规模数据的机制。Hive 定义了简单的类 SQL 查询语言，称为 HQL，它允许熟悉 SQL 的用户查询数据。同时，这个语言也允许熟悉 MapReduce 开发者的开发自定义的 mapper 和 reducer 来处理内建的 mapper 和 reducer 无法完成的复杂的分析工作

简单来讲，Hive提供了一种高级的类似SQL的语言，来执行一些以前必须要自己写Map,Reduce程序才能实现的功能，大大简化了数据处理的难度(MapReduce程序很难写)， 但是，Hive的实时性很差，适合离线处理，数据分析和数据挖掘等对实时性要求不高的任务。

## Pig

提供类似SQL的语言叫做`Pig Latin`, 可以把类SQL的语言转化程优化处理过的MapReduce运算。

Pig是一种大规模数据集的脚本语言，它实际上提供了一整套脚本语言的特性，用来处理海量的数据。

## Zookeeper

Zookeeper的目的是提供一些工具集，用来建立安全处理局部故障的分布式应用。 使用Zookeeper, 我们可以更容易的自己实现一个分布式的应用。

参考文献:[1](http://www.cnblogs.com/wuxl360/p/5817471.html)

